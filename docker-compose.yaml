version: '3.8'

x-airflow-common: &airflow-common
  build: 
    context: ./airflow
    dockerfile: Dockerfile
  environment:
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
    - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq4jTzPNJXLiVr3AgK7JQUEzY_LgG0A4=
    - AIRFLOW__CORE__LOAD_EXAMPLES=false
    - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
    - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=true
    - AIRFLOW_CONN_SPORT_ADVANTAGES_DB=postgresql://${SPORT_POSTGRES_USER}:${SPORT_POSTGRES_PASSWORD}@business-postgres:${SPORT_POSTGRES_INTERNAL_PORT}/${SPORT_POSTGRES_DB}
    - AIRFLOW_CONN_REDPANDA=kafka://redpanda:9092
    - AIRFLOW_CONN_SPARK_DEFAULT=spark://spark-master:7077
    - AIRFLOW__METRICS__STATSD_ON=True
    - AIRFLOW__METRICS__STATSD_HOST=statsd
    - AIRFLOW__METRICS__STATSD_PORT=8125
    - AIRFLOW__METRICS__STATSD_PREFIX=airflow
    - AIRFLOW_CONFIG=/opt/airflow/airflow.cfg
    - MINIO_ROOT_USER=${MINIO_ROOT_USER}
    - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    - DB_HOST=${SPORT_POSTGRES_HOST}
    - DB_USER=${SPORT_POSTGRES_USER}
    - DB_PASSWORD=${SPORT_POSTGRES_PASSWORD}
    - DB_NAME=${SPORT_POSTGRES_DB}
    - DB_PORT=${SPORT_POSTGRES_INTERNAL_PORT}
    - GUNICORN_TIMEOUT=300
  volumes:
    - ./airflow/config:/opt/airflow/config
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
  depends_on:
    - airflow-postgres
    - spark-master
    - minio
  networks:
    - sport_network

services:
 # BDD Postgresql pour Airflow
  airflow-postgres:
    image: postgres:14
    container_name: sport-advantages-airflow-postgres
    restart: always
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - airflow_postgres_data:/var/lib/postgresql/data
    ports:
      - "${AIRFLOW_POSTGRES_PORT}:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    networks:
      - sport_network

  # Base de données PostgreSQL
  business-postgres:
    image: postgres:14
    container_name: business-postgres
    restart: always
    environment:
      POSTGRES_USER: ${SPORT_POSTGRES_USER}
      POSTGRES_PASSWORD: ${SPORT_POSTGRES_PASSWORD}
      POSTGRES_DB: ${SPORT_POSTGRES_DB}
    ports:
      - "${SPORT_POSTGRES_PORT}:${SPORT_POSTGRES_INTERNAL_PORT}"
    volumes:
      - business_postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
      - ./postgres-config/postgresql.conf:/etc/postgresql/postgresql.conf
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c shared_preload_libraries=pgoutput
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${SPORT_POSTGRES_USER} -d ${SPORT_POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - sport_network

  # Redpanda - Alternative à Kafka pour le streaming de données
  redpanda:
    image: redpandadata/redpanda:latest
    container_name: sport-advantages-redpanda
    command:
    - redpanda
    - start
      --smp=1
      --memory=1G
      --reserve-memory=0M
      --overprovisioned
      --node-id=0
      --check=false
      --kafka-addr PLAINTEXT://0.0.0.0:9092,OUTSIDE://0.0.0.0:19092
      --advertise-kafka-addr PLAINTEXT://redpanda:9092,OUTSIDE://localhost:19092
      --rpc-addr redpanda:33145
      --advertise-rpc-addr redpanda:33145
      --set redpanda.enable_transactions=true
      --set redpanda.enable_idempotence=true
    ports:
      - "9092:9092"
      - "19092:19092"
      - "33145:33145"
    volumes:
      - redpanda_data:/var/lib/redpanda/data
    depends_on:
      business-postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "rpk cluster health | grep -E 'Healthy:.+true' || exit 1"]
      interval: 15s
      timeout: 3s
      retries: 5
      start_period: 5s
    networks:
      - sport_network

  # Redpanda Console - Interface UI pour Redpanda
  redpanda-console:
    image: redpandadata/console:latest
    container_name: sport-advantages-redpanda-console
    depends_on:
      redpanda:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      - KAFKA_BROKERS=redpanda:9092
    networks:
      - sport_network

  # Debezium - Pour capturer les changements de la base de données (CDC)
  debezium:
    image: debezium/connect:2.4
    container_name: sport-advantages-debezium
    depends_on:
      business-postgres:
        condition: service_healthy
      redpanda:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      - CONNECT_REST_ADVERTISED_HOST_NAME=debezium
      - GROUP_ID=${DEBEZIUM_GROUP_ID}
      - BOOTSTRAP_SERVERS=redpanda:9092
      - CONFIG_STORAGE_TOPIC=${DEBEZIUM_CONFIG_STORAGE_TOPIC}
      - OFFSET_STORAGE_TOPIC=${DEBEZIUM_OFFSET_STORAGE_TOPIC}
      - STATUS_STORAGE_TOPIC=${DEBEZIUM_STATUS_STORAGE_TOPIC}
      - CONNECT_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - CONNECT_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - SPORT_POSTGRES_HOST=${SPORT_POSTGRES_HOST}
      - SPORT_POSTGRES_PORT=${SPORT_POSTGRES_PORT}
      - SPORT_POSTGRES_USER=${SPORT_POSTGRES_USER}
      - SPORT_POSTGRES_PASSWORD=${SPORT_POSTGRES_PASSWORD}
      - SPORT_POSTGRES_DB=${SPORT_POSTGRES_DB}
    healthcheck: 
      test: ["CMD-SHELL", "curl -f http://debezium:8083/connectors"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 30s
    volumes:
      - ./debezium/init-debezium.sh:/init-debezium.sh
    command: ["/init-debezium.sh"]
    networks:
      - sport_network

  # Pour valider les données de transport et importation de données salariés 
  init-db-commute-validation:
    build:
      context: ./commute_validation
      dockerfile: Dockerfile
    container_name: sport-advantages-init-db
    depends_on:
      business-postgres:
        condition: service_healthy
    volumes:
      - ./commute_validation:/app
    environment:
      - DB_HOST=${SPORT_POSTGRES_HOST}
      - DB_USER=${SPORT_POSTGRES_USER}
      - DB_PASSWORD=${SPORT_POSTGRES_PASSWORD}
      - DB_NAME=${SPORT_POSTGRES_DB}
      - DB_PORT=${SPORT_POSTGRES_INTERNAL_PORT}
      - GOOGLE_MAPS_API_KEY=${GOOGLE_MAPS_API_KEY}
    networks:
      - sport_network

  # Service Python pour générer les données et les insérer dans PostgreSQL
  data-generator:
    build:
      context: ./activity_generator
      dockerfile: Dockerfile
    container_name: sport-advantages-data-generator
    depends_on:
      init-db-commute-validation:
        condition: service_completed_successfully
      debezium:
        condition: service_healthy
    volumes:
      - ./activity_generator:/app
    environment:
      - DB_HOST=${SPORT_POSTGRES_HOST}
      - DB_USER=${SPORT_POSTGRES_USER}
      - DB_PASSWORD=${SPORT_POSTGRES_PASSWORD}
      - DB_PORT=${SPORT_POSTGRES_INTERNAL_PORT}
      - DB_NAME=${SPORT_POSTGRES_DB}
    networks:
      - sport_network
  
  # Spark Master
  spark-master:
    image: bitnami/spark:3.2.3
    container_name: sport-advantages-spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_METRICS_ON=true
      - SPARK_METRICS_CONF=/opt/bitnami/spark/conf/metrics.properties
      - JAVA_TOOL_OPTIONS=-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=7203 -Dcom.sun.management.jmxremote.rmi.port=7203 -Djava.rmi.server.hostname=spark-master
    volumes:
      - spark_master_data:/recovery
      - ./monitoring/spark/metrics.properties:/opt/bitnami/spark/conf/metrics.properties
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 10s
      timeout: 5s
      retries: 5
    mem_limit: 1g
    cpus: 1.0
    ports:
      - "8090:8080"
      - "7077:7077"
      - "7203:7203"
    networks:
      - sport_network
   
  # Spark Worker
  spark-worker:
    image: bitnami/spark:3.2.3
    container_name: sport-advantages-spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
      - SPARK_EXECUTOR_HEARTBEAT_INTERVAL=10s
      - SPARK_NETWORK_TIMEOUT=800s
      - SPARK_TASK_MAXFAILURES=4                        
      - SPARK_SPECULATION=true 
      - SPARK_RPC_AUTHENTICATION_ENABLED=no       
      - SPARK_RPC_ENCRYPTION_ENABLED=no           
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no 
      - SPARK_SSL_ENABLED=no 
      - SPARK_METRICS_ON=true
      - SPARK_METRICS_CONF=/opt/bitnami/spark/conf/metrics.properties
      - JAVA_TOOL_OPTIONS=-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=7204 -Dcom.sun.management.jmxremote.rmi.port=7204 -Djava.rmi.server.hostname=spark-worker
    volumes:
      - ./monitoring/spark/metrics.properties:/opt/bitnami/spark/conf/metrics.properties
    mem_limit: 2g
    cpus: 2.0
    ports:
      - "7204:7204"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - sport_network

  scala-runner:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: sport-advantages-scala-runner
    environment:
      - KAFKA_SERVERS=redpanda:9092
      # - TOPIC_NAME=${DEBEZIUM_OFFSET_STORAGE_TOPIC}
      - TOPIC_NAME=${TOPIC_NAME}
      - DB_HOST=${SPORT_POSTGRES_HOST}
      - DB_USER=${SPORT_POSTGRES_USER}
      - DB_PASSWORD=${SPORT_POSTGRES_PASSWORD}
      - DB_NAME=${SPORT_POSTGRES_DB}
      - DB_PORT=${SPORT_POSTGRES_INTERNAL_PORT}
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD}
    depends_on:
      minio:
        condition: service_healthy
      debezium:
        condition: service_healthy
    volumes:
      - ./spark:/scripts
      - delta_volume:/data
    networks:
      - sport_network

  slack-notifier:
    build:
      context: ./slack_notifier
      dockerfile: Dockerfile
    container_name: sport-advantages-slack-notifier
    volumes:
      - ./slack_notifier:/app
    environment:
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}
      - KAFKA_TOPIC=sport.sport_advantages.sport_activities
    depends_on:
      - redpanda
    networks:
      - sport_network

  # Minio comme stockage compatible S3 pour Delta Lake
  minio:
    image: minio/minio
    container_name: sport-advantages-minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - minio_data:/data
    networks:
      - sport_network

  # Initialisation de MinIO
  minio-init:
    image: minio/mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc config host add myminio http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD}) do sleep 1; done;
      /usr/bin/mc mb myminio/delta-tables --ignore-existing;
      /usr/bin/mc policy set public myminio/delta-tables;
      mc mb myminio/delta-tables --ignore-existing;
      mc policy set public myminio/delta-tables;
      mc ls myminio/delta-tables;
      echo 'MinIO initialization complete';
      exit 0;
      "
    networks:
      - sport_network

  # Airflow Webserver
  airflow-webserver:
    <<: *airflow-common
    container_name: sport-advantages-airflow-webserver
    command: webserver
    restart: always
    depends_on:
      airflow-postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    ports:
      - "8081:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - sport_network

  # Airflow Scheduler
  airflow-scheduler:
    <<: *airflow-common
    container_name: sport-advantages-airflow-scheduler
    command: scheduler
    depends_on:
      - airflow-postgres
      - airflow-init
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - sport_network

  # Airflow Init (initialise la base de données et crée le premier utilisateur)
  airflow-init:
    <<: *airflow-common
    container_name: sport-advantages-airflow-init
    entrypoint: /bin/bash
    command:
      - -c
      - |
        set -e
        if [[ -z "$(ls -A /opt/airflow/logs)" ]]; then
          mkdir -p /opt/airflow/logs
        fi
        airflow db init
        airflow users create \
          --username admin \
          --password admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com
    restart: on-failure
    mem_limit: 4g
    cpus: 2.0  
    depends_on:
      - airflow-postgres
    networks:
      - sport_network

  # Trino - SQL query engine 
  trino:
    build:
      context: ./trino
      dockerfile: Dockerfile
    container_name: sport-advantages-trino
    hostname: trino
    ports:
      - "8100:8080"
    volumes:
      - ./trino/etc:/etc/trino
      - trino-metastore:/tmp/trino-metastore
    environment:
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD}
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - SPORT_POSTGRES_DB=${SPORT_POSTGRES_DB}
      - SPORT_POSTGRES_USER=${SPORT_POSTGRES_USER}
      - SPORT_POSTGRES_INTERNAL_PORT=${SPORT_POSTGRES_INTERNAL_PORT}
      - SPORT_POSTGRES_PASSWORD=${SPORT_POSTGRES_PASSWORD}
    depends_on:
      - minio
      - business-postgres
    networks:
      sport_network:
        aliases:
          - trino
    
 # Service PostgreSQL pour les métadonnées de Superset
  superset-postgres:
    image: postgres:14
    container_name: superset-postgres
    environment:
      - POSTGRES_USER=superset
      - POSTGRES_PASSWORD=superset
      - POSTGRES_DB=superset
    ports:
      - "${SUPERSET_POSTGRES_PORT}:5432"
    volumes:
      - superset_postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    networks:
      - sport_network

  superset:
    build:
      context: ./superset
      dockerfile: Dockerfile
    container_name: sport-advantages-superset
    restart: always
    depends_on:
      superset-postgres:
        condition: service_healthy
      trino:
        condition: service_started
    environment:
      - SUPERSET_SECRET_KEY=ThisIsAVeryLongAndSecureKeyForOurSupersetInstance1234567890
      - SUPERSET_DATABASE_URI=postgresql+psycopg2://superset:superset@superset-postgres:5432/superset
      - POSTGRES_USER=${SPORT_POSTGRES_USER}
      - POSTGRES_PASSWORD=${SPORT_POSTGRES_PASSWORD}
      - POSTGRES_DB=${SPORT_POSTGRES_DB}
      - POSTGRES_HOST=business-postgres
      - POSTGRES_PORT=${SPORT_POSTGRES_INTERNAL_PORT}
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - PYTHONPATH=/app
      - FLASK_APP=superset.app:create_app()
      - FLASK_ENV=production
      - SUPERSET_ENV=development
      - TRINO_HOST=trino
      - TRINO_PORT=8080
      - TRINO_USER=trino
      - TRINO_CATALOG=postgresql,minio
    ports:
      - "8088:8088"
    volumes:
      - ./superset/superset_data:/app/superset_home
      - ./superset/superset_config.py:/app/superset/superset_config.py
      - ./superset/docker/docker-entrypoint.sh:/app/docker-entrypoint.sh
      - ./superset/docker-init.d:/app/docker-init.d
      - ./superset/dashboards:/app/superset_home/dashboards
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8088/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - sport_network

  # Prometheus pour la collecte de métriques
  prometheus:
    image: prom/prometheus:latest
    container_name: sport-advantages-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--web.enable-lifecycle'
    depends_on:
      - cadvisor
    networks:
      - sport_network

  # cAdvisor pour les métriques des conteneurs
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: sport-advantages-cadvisor
    ports:
      - "8082:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    devices:
      - /dev/kmsg:/dev/kmsg
    privileged: true
    networks:
      - sport_network

  # Grafana pour la visualisation
  grafana:
    image: grafana/grafana:latest
    container_name: sport-advantages-grafana
    ports:
      - "3000:3000"
    volumes:
      - ./monitoring/grafana/volume/data:/grafana
      - ./monitoring/grafana/volume/datasources:/grafana/datasources
      - ./monitoring/grafana/volume/dashboards:/grafana/dashboards
      - ./monitoring/grafana/volume/provisioning:/grafana/provisioning
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    depends_on:
      - prometheus
    networks:
      - sport_network

  # Pour les métriques Airflow
  statsd:
    image: prom/statsd-exporter:latest
    container_name: sport-advantages-statsd
    command: "--statsd.listen-udp=:8125 --web.listen-address=:9102"
    ports:
      - "9102:9102"
      - "8125:8125/udp"
    networks:
      - sport_network


  # Exporteur des métriques instance postgresql pour les données métier
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter
    container_name: postgres-exporter
    environment:
      - DATA_SOURCE_NAME=postgresql://${SPORT_POSTGRES_USER}:${SPORT_POSTGRES_PASSWORD}@business-postgres:5432/${SPORT_POSTGRES_DB}?sslmode=disable
    ports:
      - "9187:9187"
    depends_on:
      business-postgres:
        condition: service_healthy
    volumes:
      - ./monitoring/postgres-exporter/postgres_exporter.yml:/postgres_exporter.yml
    networks:
      - sport_network

  # Exporteur des métriques instance postgresql pour Airflow
  postgres-airflow-exporter:
    image: prometheuscommunity/postgres-exporter
    container_name: postgres-airflow-exporter
    environment:
      - DATA_SOURCE_NAME=postgresql://airflow:airflow@airflow-postgres:5432/airflow?sslmode=disable
    ports:
      - "9188:9187" 
    depends_on:
      airflow-postgres:
        condition: service_healthy
    networks:
      - sport_network


volumes:
  business_postgres_data:
  airflow_postgres_data:
  minio_data:
  redpanda_data:
  spark_master_data:
  delta_volume:
  superset_postgres_data:
  trino-metastore:
  grafana_data:


networks:
  sport_network:
    driver: bridge
    name: sport_network